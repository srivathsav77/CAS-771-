{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "! pip install tensorflow\n",
    "from numpy import concatenate\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "import tensorflow as tf\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix , precision_score, recall_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Load the input image data and test data from tensorflow cifar dataset\n",
    "(x_train, yoriginal), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(\"Shape of training input images\",x_train.shape)\n",
    "\n",
    "#Load the given noisy labels\n",
    "noiselabels=pd.read_json(\"cifar10_noisy_labels_task1.json\")\n",
    "y_train=np.array(noiselabels)\n",
    "\n",
    "print(\"Shape of training noise labels\",y_train.shape)\n",
    "print(\"Shape of test dataset images\",x_test.shape)\n",
    "print(\"Shape of test dataset labels\",y_test.shape)\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "## Split training dataset into labeled and unlabeled dataset\n",
    "# As the first set of 10000 samples has given less training loss when trained separately using cnn model, hence using that set as labelled dataset.\n",
    "x_train_lab, x_test_unlab, y_train_lab, y_test_unlab = train_test_split(x_train, y_train, test_size=0.80, stratify=y_train)\n",
    "\n",
    "print(\"Length of labelled data\",len(y_train_lab))\n",
    "print(\"Length of unlabelled data\",len(y_test_unlab))\n",
    "\n",
    "## Creating the training input image dataset \n",
    "X_train_mixed = concatenate((x_train_lab, x_test_unlab))\n",
    "\n",
    "## creating \"no label\" for the unlabeled data\n",
    "nolabel = [-1 for _ in range(len(y_test_unlab))]\n",
    "\n",
    "## Creating combined training dataset labels\n",
    "y_train_mixed = concatenate((y_train_lab[:,0], nolabel))\n",
    "print(\"Length of combined labelled and unlabelled data\", len(y_train_mixed))\n",
    "\n",
    "## Defining the first labelpropagation model\n",
    "model_propa = LabelPropagation(gamma=.25)\n",
    "\n",
    "## Fit our model on training dataset\n",
    "nsamples, nx, ny ,nz = X_train_mixed.shape\n",
    "d2_train_dataset = X_train_mixed.reshape((nsamples,nx*ny*nz))\n",
    "model_propa.fit(d2_train_dataset, y_train_mixed)\n",
    "LEN=4980\n",
    "print(\"Done\")\n",
    "\n",
    "## Define labels for entire training dataset data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tran_labels = model_propa.transduction_\n",
    "dummy=pd.get_dummies(tran_labels)\n",
    "print(\"New labels obtained for training set after labelpropagation\\n\",dummy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of training input images (50000, 32, 32, 3)\n",
      "Shape of training noise labels (50000, 1)\n",
      "Shape of test dataset images (10000, 32, 32, 3)\n",
      "Shape of test dataset labels (10000, 1)\n",
      "Length of labelled data 10000\n",
      "Length of unlabelled data 40000\n",
      "Length of combined labelled and unlabelled data 50000\n",
      "Done\n",
      "New labels obtained for training set after labelpropagation\n",
      "        0  1  2  3  4  5  6  7  8  9\n",
      "0      0  0  0  0  1  0  0  0  0  0\n",
      "1      0  0  1  0  0  0  0  0  0  0\n",
      "2      0  0  0  0  0  0  1  0  0  0\n",
      "3      1  0  0  0  0  0  0  0  0  0\n",
      "4      0  1  0  0  0  0  0  0  0  0\n",
      "...   .. .. .. .. .. .. .. .. .. ..\n",
      "49995  0  0  0  0  0  0  1  0  0  0\n",
      "49996  0  0  0  0  0  0  0  0  0  1\n",
      "49997  1  0  0  0  0  0  0  0  0  0\n",
      "49998  1  0  0  0  0  0  0  0  0  0\n",
      "49999  0  0  0  0  0  0  0  0  1  0\n",
      "\n",
      "[50000 rows x 10 columns]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/srv/conda/envs/saturn/lib/python3.9/site-packages/sklearn/semi_supervised/_label_propagation.py:316: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T00:06:51.844550Z",
     "iopub.status.busy": "2022-04-21T00:06:51.844262Z",
     "iopub.status.idle": "2022-04-21T00:18:41.509735Z",
     "shell.execute_reply": "2022-04-21T00:18:41.509048Z",
     "shell.execute_reply.started": "2022-04-21T00:06:51.844523Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Create CNN Model\n",
    "from tensorflow.keras import  layers, models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), dtype='float32', activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='softmax'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "## Compile The model\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "## fit the model\n",
    "import numpy as np\n",
    "history=model.fit(x_train, dummy, batch_size=32, epochs=50)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T00:18:55.946926Z",
     "iopub.status.busy": "2022-04-21T00:18:55.946642Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Predicting the test dataset\n",
    "model.summary()\n",
    "true_testlabels=pd.get_dummies(y_test[:,0])\n",
    "test_loss, test_acc= model.evaluate(x_test,true_testlabels)\n",
    "print('Test Data loss:', test_loss)\n",
    "print('Test Data accuracy:', test_acc)\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "pd.DataFrame(history_dict).plot(figsize=(10,6))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 2)\n",
    "plt.title('Accuracy and loss for training', fontsize=16)\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Accuracy and loss percentage', rotation=90, fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "ypred = model.predict(x_test)\n",
    "ypred=np.argmax(ypred,axis=1)\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T19:23:36.275980Z",
     "iopub.status.busy": "2022-04-06T19:23:36.275690Z",
     "iopub.status.idle": "2022-04-06T19:23:39.156160Z",
     "shell.execute_reply": "2022-04-06T19:23:39.155565Z",
     "shell.execute_reply.started": "2022-04-06T19:23:36.275957Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from  matplotlib import pyplot \n",
    "\n",
    "for i in range(2):\n",
    "    # define subplot\n",
    "    pyplot.subplot(330+1+i)\n",
    "    # plot test data\n",
    "    pyplot.title(ypred[i])\n",
    "    pyplot.imshow(x_test[i])\n",
    "# show the figure\n",
    "pyplot.show()\n"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T19:34:24.903040Z",
     "iopub.status.busy": "2022-04-06T19:34:24.902472Z",
     "iopub.status.idle": "2022-04-06T19:34:25.163894Z",
     "shell.execute_reply": "2022-04-06T19:34:25.162790Z",
     "shell.execute_reply.started": "2022-04-06T19:34:24.902982Z"
    },
    "tags": []
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}